{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "from algorithms import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement minimization methods on ROSENBROCK using x0 = [1.2, 1.2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the first starting point x0 = [1.2, 1.2]\n",
    "x0 = np.array([1.2, 1.2])\n",
    "# Print the starting point\n",
    "# print(\"Starting point: x0 =\", x0,'\\n')\n",
    "print(\"COST BEFORE OPTIMIZATION:\",rosenbrock(x0),'\\n')\n",
    "\n",
    "# Find the optimal point, number of iterations, and elapsed time using the steepest_descent_back_tracking method\n",
    "# x_opt, iter, elapsed_time = steepest_descent_back_tracking(x0,c=1e-4, rho=0.5)\n",
    "\n",
    "x_opt, iter, elapsed_time, x_vals1 = steepest_descent_back_tracking(x0,rosenbrock, rosenbrock_gradient, epsilon=1e-8, max_iter=1000, c=1e-4, rho=0.5)\n",
    "# Print the results\n",
    "results_out('Steepest Descent',x_opt,iter,elapsed_time, rosenbrock, rosenbrock_gradient, x_vals1, plotGraph=False)\n",
    "\n",
    "\n",
    "# Find the optimal point, number of iterations, and elapsed time using the newton_back_tracking method\n",
    "x_opt, iter, elapsed_time, x_vals2 = newton_back_tracking(x0, rosenbrock, rosenbrock_gradient, rosenbrock_hessian, epsilon=1e-8, max_iter=1000, c=1e-4, rho=0.5)\n",
    "\n",
    "# Print the results\n",
    "results_out('Newton',x_opt,iter,elapsed_time,rosenbrock, rosenbrock_gradient, x_vals2, plotGraph=False)\n",
    "\n",
    "\n",
    "plot_all(rosenbrock,x_vals1,x_vals2,'ROSENBROCK using x0 = [1.2, 1.2]')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement minimization methods on ROSENBROCK using x0 = [-1.2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([-1.2, 1])\n",
    "\n",
    "# Print the starting point\n",
    "# print(\"Starting point: x0 =\", x0,'\\n')\n",
    "print(\"COST BEFORE OPTIMIZATION:\",rosenbrock(x0),'\\n')\n",
    "\n",
    "# Find the optimal point, number of iterations, and elapsed time using the newton_back_tracking method\n",
    "x_opt, iter, elapsed_time, x_vals = newton_back_tracking(x0, rosenbrock, rosenbrock_gradient, rosenbrock_hessian, epsilon=1e-8, max_iter=1000, c=1e-4, rho=0.5)\n",
    "\n",
    "# Print the results\n",
    "results_out('Newton',x_opt,iter,elapsed_time, rosenbrock, rosenbrock_gradient,x_vals, plotGraph=False)\n",
    "\n",
    "# Find the optimal point, number of iterations, and elapsed time using the steepest_descent_back_tracking method\n",
    "x_opt, iter, elapsed_time, x_vals = steepest_descent_back_tracking(x0,rosenbrock, rosenbrock_gradient, epsilon=1e-8, max_iter=1000, c=1e-4, rho=0.5)\n",
    "# Print the results\n",
    "results_out('Steepest Descent',x_opt,iter,elapsed_time, rosenbrock, rosenbrock_gradient, x_vals, plotGraph=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement minimization methods on CHAINED ROSENBROCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initial guess for the optimization problem\n",
    "d = 1\n",
    "n = 10 ** d\n",
    "x0 = np.zeros(n)\n",
    "for i in range(n):\n",
    "    if (i % 2) == 1:\n",
    "        x0[i] = -1.2\n",
    "    else:\n",
    "        x0[i] = 1.0\n",
    "\n",
    "# Print the starting point\n",
    "# print(\"Starting point: x0 =\", x0,'\\n')\n",
    "print(\"COST BEFORE OPTIMIZATION:\",chained_rosenbrock(x0),'\\n')\n",
    "\n",
    "# Find the optimal point, number of iterations, and elapsed time using the newton_back_tracking method\n",
    "x_opt, iter, elapsed_time, x_vals = newton_back_tracking(x0, chained_rosenbrock, chained_rosenbrock_gradient, chained_rosenbrock_hessian, epsilon=1e-8, max_iter=1000, c=1e-4, rho=0.5)\n",
    "\n",
    "# Print the results\n",
    "results_out('Newton',x_opt,iter,elapsed_time, chained_rosenbrock, chained_rosenbrock_gradient, x_vals, plotGraph=True)\n",
    "\n",
    "# Find the optimal point, number of iterations, and elapsed time using the steepest_descent_back_tracking method\n",
    "# x_opt, iter, elapsed_time = steepest_descent_back_tracking(x0,c=1e-4, rho=0.5)\n",
    "\n",
    "x_opt, iter, elapsed_time, x_vals = steepest_descent_back_tracking(x0,chained_rosenbrock, chained_rosenbrock_gradient, epsilon=1e-8, max_iter=1000, c=1e-4, rho=0.5)\n",
    "# Print the results\n",
    "results_out('Steepest Descent',x_opt,iter,elapsed_time, chained_rosenbrock, chained_rosenbrock_gradient, x_vals, plotGraph=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement minimization methods on GENERALIZED BROWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initial guess for the optimization problem\n",
    "d = 2\n",
    "n = 10 ** d\n",
    "x0 = np.zeros(n)\n",
    "for i in range(n):\n",
    "    if (i % 2) == 1:\n",
    "        x0[i] = -1.0\n",
    "    else:\n",
    "        x0[i] = 1.0\n",
    "\n",
    "# Print the starting point\n",
    "# print(\"Starting point: x0 =\", x0,'\\n')\n",
    "print(\"COST BEFORE OPTIMIZATION:\",generalized_brown(x0),'\\n')\n",
    "# Find the optimal point, number of iterations, and elapsed time using the newton_back_tracking method\n",
    "x_opt, iter, elapsed_time, x_vals = newton_back_tracking(x0, generalized_brown, generalized_brown_gradient, generalized_brown_hessian, epsilon=1e-8, max_iter=1000, c=1e-4, rho=0.5)\n",
    "\n",
    "# Print the results\n",
    "results_out('Newton',x_opt,iter,elapsed_time, generalized_brown,generalized_brown_gradient, x_vals, plotGraph=False)\n",
    "\n",
    "# Find the optimal point, number of iterations, and elapsed time using the steepest_descent_back_tracking method\n",
    "x_opt, iter, elapsed_time, x_vals = steepest_descent_back_tracking(x0,generalized_brown, generalized_brown_gradient, epsilon=1e-8, max_iter=1000, c=1e-4, rho=0.5)\n",
    "# Print the results\n",
    "results_out('Steepest Descent',x_opt,iter,elapsed_time, generalized_brown,generalized_brown_gradient, x_vals, plotGraph=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement minimization methods on PROBLEM 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initial guess for the optimization problem\n",
    "d = 3\n",
    "n = 10 ** d\n",
    "x0 = np.zeros(n)\n",
    "for l in range(n):\n",
    "    x0[l] = 2\n",
    "\n",
    "# Print the starting point\n",
    "# print(\"Starting point: x0 =\", x0,'\\n')\n",
    "\n",
    "print(\"COST BEFORE OPTIMIZATION:\",problem76(x0),'\\n')\n",
    "\n",
    "# Find the optimal point, number of iterations, and elapsed time using the newton_back_tracking method\n",
    "x_opt, iter, elapsed_time, x_vals = newton_back_tracking(x0, problem76, problem76_gradient, problem76_hessian, epsilon=1e-8, max_iter=1000, c=1e-4, rho=0.5)\n",
    "\n",
    "# Print the results\n",
    "results_out('Newton',x_opt,iter,elapsed_time, problem76, problem76_gradient, x_vals, plotGraph=False)\n",
    "\n",
    "# Find the optimal point, number of iterations, and elapsed time using the steepest_descent_back_tracking method\n",
    "# x_opt, iter, elapsed_time = steepest_descent_back_tracking(x0,c=1e-4, rho=0.5)\n",
    "\n",
    "x_opt, iter, elapsed_time, x_vals = steepest_descent_back_tracking(x0,problem76, problem76_gradient, epsilon=1e-8, max_iter=1000, c=1e-4, rho=0.5)\n",
    "# Print the results\n",
    "results_out('Steepest Descent',x_opt,iter,elapsed_time, problem76, problem76_gradient, x_vals, plotGraph=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7af9525b5e638f66f97bbc4bd01d94d236c015f4bf0deb5835770f8430b16297"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
